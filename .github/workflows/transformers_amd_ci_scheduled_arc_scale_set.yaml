name: Self-hosted runner scale set (scheduled-amd)

# Note: For the AMD CI, we rely on a caller workflow and on the workflow_call event to trigger the CI
# ref: https://github.com/huggingface/transformers/blob/main/.github/workflows/self-scheduled-amd-mi300-caller.yml

on:
  workflow_call:
    inputs:
      job:
        required: true
        type: string
      slack_report_channel:
        required: true
        type: string
      runner_scale_set:
        required: true
        type: string
      docker:
        required: true
        type: string
      ci_event:
        required: true
        type: string

env:
  HF_HOME: /mnt/cache
  TRANSFORMERS_IS_CI: yes
  OMP_NUM_THREADS: 8
  MKL_NUM_THREADS: 8
  RUN_SLOW: yes
  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}
  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}
  NUM_SLICES: 2

jobs:
  check_runners:
    name: Check Runners
    strategy:
      matrix:
        machine_type: [1gpu]
    runs-on: ${{ inputs.runner_scale_set }}-${{ matrix.machine_type }}-ossci
    container:
      image: huggingface/transformers-pytorch-amd-gpu
      options: --device /dev/kfd --device /dev/dri --env-file /etc/podinfo/gha-gpu-isolation-settings --shm-size "16gb" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/
    steps:
      - name: ROCM-INFO
        run: rocminfo | grep "Agent" -A 14

      - name: Show ROCR environment
        run: |
          echo "ROCR: $ROCR_VISIBLE_DEVICES"
          echo "HIP:  $HIP_VISIBLE_DEVICES"